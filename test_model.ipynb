{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926ca4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from tqdm import tqdm\n",
    "from json_repair import repair_json\n",
    "\n",
    "import torch\n",
    "from datasets import load_from_disk\n",
    "from torchmetrics import MeanAbsoluteError\n",
    "from torchmetrics.text import EditDistance, BERTScore\n",
    "from torchmetrics.classification import BinaryAccuracy\n",
    "from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor\n",
    "from qwen_vl_utils import process_vision_info\n",
    "\n",
    "from dataset_formatter import format_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76c336f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = \"~/.cache/huggingface/hub/my_tmp_dataset_test\"\n",
    "test_dataset = load_from_disk(dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2d6eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_modified = [format_data(sample) for sample in tqdm(test_dataset)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa89fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_modified[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ec32fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"Qwen/Qwen2.5-VL-7B-Instruct\"\n",
    "model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=0,\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d236f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter_path = \"qwen2.5-7b-instruct-trl-watermarks\"\n",
    "model.load_adapter(adapter_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a5b5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_adapter('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b24fac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.disable_adapters()\n",
    "model.enable_adapters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc66e4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_from_sample(model, processor, sample, max_new_tokens=1024, device=\"cuda\"):\n",
    "    # Prepare the text input by applying the chat template\n",
    "    text_input = processor.apply_chat_template(\n",
    "        sample[\"messages\"], \n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "    )\n",
    "    # Process the visual input from the sample\n",
    "    image_inputs, _ = process_vision_info(sample[\"messages\"])\n",
    "\n",
    "    # Prepare the inputs for the model\n",
    "    model_inputs = processor(\n",
    "        text=[text_input],\n",
    "        images=image_inputs,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(\n",
    "        device\n",
    "    )  # Move inputs to the specified device\n",
    "\n",
    "    # Generate text with the model\n",
    "    generated_ids = model.generate(**model_inputs, max_new_tokens=max_new_tokens)\n",
    "\n",
    "    # Trim the generated ids to remove the input ids\n",
    "    trimmed_generated_ids = [out_ids[len(in_ids) :] for in_ids, out_ids in zip(model_inputs.input_ids, generated_ids)]\n",
    "\n",
    "    # Decode the output text\n",
    "    output_text = processor.batch_decode(\n",
    "        trimmed_generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "    )\n",
    "    return json.loads(repair_json(output_text[0]))  # Return the first decoded output text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f296ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = generate_text_from_sample(model, processor, test_dataset_modified[238] )\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0b6484",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_modified[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095d6b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "image_path = \"assets/should-you-watermark-images-5.jpg\"\n",
    "img = Image.open(image_path)\n",
    "img = {\"images\": [img.resize((512, 341))], \"texts\": [{\"assistant\": \"\"}]}\n",
    "img1 = img['images'][0]\n",
    "img1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6781a3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = BinaryAccuracy()\n",
    "mae_error = MeanAbsoluteError()\n",
    "levenshtein = EditDistance()\n",
    "bertscore_object = BERTScore(model_name_or_path=\"roberta-base\")\n",
    "bertscore_style = BERTScore(model_name_or_path=\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377a433e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted = 0\n",
    "keys = {'watermarks', \"text\", \"main object\", \"style\"}\n",
    "for sample in tqdm(test_dataset_modified[:1000]):\n",
    "    output = generate_text_from_sample(model, processor, sample)\n",
    "    target = json.loads(repair_json(sample[\"messages\"][2][\"content\"][0][\"text\"]))\n",
    "    if not isinstance(output, dict) or not set(output.keys()) == keys or not set(target.keys()) == keys:\n",
    "        corrupted += 1\n",
    "        continue\n",
    "    accuracy(torch.tensor([int(output['watermarks'] == target[\"watermarks\"])]), torch.tensor([1]))\n",
    "    mae_error(torch.tensor([output['watermarks']]), torch.tensor([target[\"watermarks\"]]))\n",
    "    levenshtein([str(output[\"text\"])], str(target['text']))\n",
    "    bertscore_object(preds=[output[\"main object\"]], target=target[\"main object\"])\n",
    "    bertscore_style(preds=[output[\"style\"]], target=target[\"style\"])\n",
    "acc = accuracy.compute()\n",
    "mae = mae_error.compute()\n",
    "lev = levenshtein.compute()\n",
    "bscore_ob = bertscore_object.compute()\n",
    "bscore_st= bertscore_style.compute()\n",
    "print(\"Watermarks accuracy:\", acc)\n",
    "print(\"Watermarks MAE:\", mae)\n",
    "print(\"Found text Levenshtein edit distance:\", lev)\n",
    "print(\"Main object BERTScore:\", bscore_ob['f1'].mean())\n",
    "print(\"Style BERTScore:\", bscore_st['f1'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07a1e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Watermarks accuracy:\", \"{:.3f}\".format(acc.item()))\n",
    "print(\"Watermarks MAE:\", \"{:.3f}\".format(mae.item()))\n",
    "print(\"Found text Levenshtein edit distance:\", \"{:.3f}\".format(lev.item()))\n",
    "print(\"Main object BERTScore:\", \"{:.3f}\".format(bscore_ob['f1'].mean().item()))\n",
    "print(\"Style BERTScore:\", \"{:.3f}\".format(bscore_st['f1'].mean().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07a1e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy.reset()\n",
    "mae_error.reset()\n",
    "levenshtein.reset()\n",
    "bertscore_object.reset()\n",
    "bertscore_style.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e09f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76d2da7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sber",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
