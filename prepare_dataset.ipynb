{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68062191",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_id = \"HuggingFaceM4/FineVision\"\n",
    "config_name = \"cocotext\"\n",
    "train_dataset = load_dataset(dataset_id, name=config_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c29b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset['train']['images'][20][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e1c229",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor\n",
    "\n",
    "model_id = \"Qwen/Qwen2.5-VL-7B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27cef10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "    model_id, torch_dtype=\"auto\", device_map=0\n",
    ")\n",
    "\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d824a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qwen_vl_utils import process_vision_info\n",
    "\n",
    "\n",
    "def generate_text_from_sample(model, processor, sample, max_new_tokens=1024, device=\"cuda\"):\n",
    "    # Prepare the text input by applying the chat template\n",
    "    text_input = processor.apply_chat_template(\n",
    "        sample[\"messages\"], \n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "    )\n",
    "\n",
    "    # Process the visual input from the sample\n",
    "    image_inputs, _ = process_vision_info(sample[\"messages\"])\n",
    "\n",
    "    # Prepare the inputs for the model\n",
    "    model_inputs = processor(\n",
    "        text=[text_input],\n",
    "        images=image_inputs,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(\n",
    "        device\n",
    "    )  # Move inputs to the specified device\n",
    "\n",
    "    # Generate text with the model\n",
    "    generated_ids = model.generate(**model_inputs, max_new_tokens=max_new_tokens)\n",
    "\n",
    "    # Trim the generated ids to remove the input ids\n",
    "    trimmed_generated_ids = [out_ids[len(in_ids) :] for in_ids, out_ids in zip(model_inputs.input_ids, generated_ids)]\n",
    "\n",
    "    # Decode the output text\n",
    "    output_text = processor.batch_decode(\n",
    "        trimmed_generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "    )\n",
    "\n",
    "    return output_text[0]  # Return the first decoded output text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9219d9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message_object = \"\"\"You are a Vision Language Model specialised in interpreting visual data from images and determining objects and people in the picture.\n",
    "Your task is to analyze the provided image and respond to queries with concise answers, without repeating the question.\n",
    "Avoid additional explanation unless absolutely necessary.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f122bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message_style = \"\"\"You are a Vision Language Model specialised in interpreting an artistic picture style.\n",
    "Your task is to analyze the provided image and respond to queries with concise answers, without repeating the question.\n",
    "Avoid additional explanation unless absolutely necessary\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba919f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data_object(sample):\n",
    "    return {\n",
    "        \"images\": [sample[\"images\"][0]],\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": [{\"type\": \"text\", \"text\": system_message_object}],\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"image\",\n",
    "                        \"image\": sample[\"images\"][0],\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": \"Who or what on this picture? Short answer.\",\n",
    "                    },\n",
    "                ],\n",
    "            },\n",
    "        ],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8651bea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data_style(sample):\n",
    "    return {\n",
    "        \"images\": [sample[\"images\"][0]],\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": [{\"type\": \"text\", \"text\": system_message_style}],\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"image\",\n",
    "                        \"image\": sample[\"images\"][0],\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": \"What artistic style is the whole picture?. Short answer.\"\n",
    "                    },\n",
    "                ],\n",
    "            },\n",
    "        ],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0db03f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset = train_dataset[\"train\"].select(range(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c0d741",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle, choice\n",
    "\n",
    "from datasets import Dataset\n",
    "import tqdm\n",
    "\n",
    "from watermark_text import watermark_text\n",
    "from add_watermark import make_watermark_pattern\n",
    "\n",
    "\n",
    "shuffle(watermark_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172fa3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for sample in tqdm.tqdm(train_dataset[\"train\"]):\n",
    "    assistant_value = sample[\"texts\"][0][\"assistant\"]\n",
    "    generated_object = generate_text_from_sample(model, processor, format_data_object(sample))\n",
    "    generated_style = generate_text_from_sample(model, processor, format_data_style(sample))\n",
    "    image, count = make_watermark_pattern(sample['images'][0], text=choice(watermark_text))\n",
    "    data.append({'images': [image], 'texts': [{'user': '',\n",
    "                                                        'assistant': '{{\"watermarks\": {}, \"text\": {}, \"main object\": {}, \"style\": {}}}'.format(count, assistant_value, generated_object, generated_style)}]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c760c39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen():\n",
    "    for d in data:\n",
    "        yield d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ac9e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset.from_generator(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fba90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['images'][121][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817ca30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['texts'][121]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8714081e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.save_to_disk('~/.cache/huggingface/hub/my_tmp_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e4ad90",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.train_test_split(train_size=10000)\n",
    "tr_ds = ds['train']\n",
    "ts_ds = ds['test']\n",
    "tr_ds.save_to_disk('~/.cache/huggingface/hub/my_tmp_dataset_train')\n",
    "ts_ds.save_to_disk('~/.cache/huggingface/hub/my_tmp_dataset_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff093bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "ds = load_from_disk(\"~/.cache/huggingface/hub/my_tmp_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5975e937",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sber",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
